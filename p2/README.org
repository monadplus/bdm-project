* Spark Application

** Execute the code

You need a mongoDB server running, if you don't have one installed, use the one provided by our project (you will need docker and docker-compose installed):

#+BEGIN_SRC sh
$ cd mongodb/
$ docker-compose up --detach
#+END_SRC

Before running spark, you need to load the datasets into mongoDB. We provided a python script to do the loading for you (see =import.py=).

#+begin_quote
If you are running your own mongoDB server, you will probably need to edit =mongoclient.py= credentials and url.
#+end_quote

#+BEGIN_SRC sh
cd src/
pip install pymongo
python3 import.py
#+END_SRC

Once the datasets are loaded into MongoDB, you can just run the spark script =main.py= which will load a standalone Spark cluster in your localhost and
execute the different KPIs. The result of the different KPIs will be stored in =out/=.

#+BEGIN_SRC sh
cd src/
pip install pyspark
python3 main.py
#+END_SRC
